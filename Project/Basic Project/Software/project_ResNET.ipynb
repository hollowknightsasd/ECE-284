{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "radical-fifty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Building model...\n",
      "ResNet_Cifar(\n",
      "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): Sequential()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        8, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantConv2d(\n",
      "          8, 32, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (weight_quant): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantConv2d(\n",
      "          32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (weight_quant): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "     \n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import *\n",
    "\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('=> Building model...')\n",
    "    \n",
    "    \n",
    "    \n",
    "batch_size = 128\n",
    "model_name = \"resnet20_quant4bit\"\n",
    "model = resnet20_quant()\n",
    "#model.conv1 = nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "#model.bn1 = bn1 = nn.BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "model.layer1[0].conv1 = QuantConv2d(8, 8, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "#model.layer1[0].conv2 = QuantConv2d(8, 8, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "#model.layer1[0].bn1 = nn.BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "model.layer1[0].bn2 = nn.Sequential()\n",
    "#model.layer1[1].conv1 = QuantConv2d(8, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "print(model)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n",
    "# CIFAR10 has 50,000 training data, and 10,000 validation data.\n",
    "\n",
    "def train(trainloader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "\n",
    "            \n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "         \n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "        \n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    adjust_list = [80, 120]\n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1        \n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "#all_params = checkpoint['state_dict']\n",
    "#model.load_state_dict(all_params, strict=False)\n",
    "#criterion = nn.CrossEntropyLoss().cuda()\n",
    "#validate(testloader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-reminder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell won't be given, but students will complete the training\n",
    "\n",
    "lr = 4e-2\n",
    "weight_decay = 1e-4\n",
    "epochs = 100\n",
    "best_prec = 0\n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "#cudnn.benchmark = True\n",
    "\n",
    "if not os.path.exists('result'):\n",
    "    os.makedirs('result')\n",
    "fdir = 'result/'+str(model_name)\n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "        \n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    train(trainloader, model, criterion, optimizer, epoch)\n",
    "    \n",
    "    # evaluate on test set\n",
    "    print(\"Validation starts\")\n",
    "    prec = validate(testloader, model, criterion)\n",
    "\n",
    "    # remember best precision and save checkpoint\n",
    "    is_best = prec > best_prec\n",
    "    best_prec = max(prec,best_prec)\n",
    "    print('best acc: {:1f}'.format(best_prec))\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec': best_prec,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, fdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b081a0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n"
     ]
    }
   ],
   "source": [
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "    def __call__(self, module, module_in):\n",
    "        self.outputs.append(module_in)\n",
    "    def clear(self):\n",
    "        self.outputs = []  \n",
    "        \n",
    "######### Save inputs from selected layer ##########\n",
    "save_output = SaveOutput()\n",
    "device = torch.device(\"cuda\" if use_gpu else \"cpu\") \n",
    "for layer in model.modules():\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        print(\"prehooked\")\n",
    "        layer.register_forward_pre_hook(save_output)       ## Input for the module will be grapped       \n",
    "####################################################\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.to(device)\n",
    "out = model(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HW\n",
    "\n",
    "#  1. Train with 4 bits for both weight and activation to achieve >90% accuracy\n",
    "#  2. Find x_int and w_int for the 2nd convolution layer\n",
    "#  3. Check the recovered psum has similar value to the un-quantized original psum\n",
    "#     (such as example 1 in W3S2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "entertaining-queensland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 8987/10000 (90%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH = \"result/resnet20_quant4bit/model_best.pth.tar\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ceramic-nigeria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 8, 32, 32])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_output.outputs[1][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "spoken-worst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0., -1., -1.],\n",
      "          [-0., -2.,  3.],\n",
      "          [-0., -2., -3.]],\n",
      "\n",
      "         [[ 2., -2.,  2.],\n",
      "          [-2., -2., -0.],\n",
      "          [-0., -2., -3.]],\n",
      "\n",
      "         [[-5., -1.,  7.],\n",
      "          [ 1.,  1.,  7.],\n",
      "          [-4.,  0.,  3.]],\n",
      "\n",
      "         [[ 0., -2., -3.],\n",
      "          [ 0., -3.,  0.],\n",
      "          [ 0., -1., -1.]],\n",
      "\n",
      "         [[-2., -2., -3.],\n",
      "          [ 4., -7., -3.],\n",
      "          [-0., -2., -3.]],\n",
      "\n",
      "         [[ 1., -1., -2.],\n",
      "          [-1.,  3., -2.],\n",
      "          [ 3., -1., -1.]],\n",
      "\n",
      "         [[ 1.,  1., -3.],\n",
      "          [ 0., -5.,  6.],\n",
      "          [ 1., -2., -0.]],\n",
      "\n",
      "         [[ 2., -2., -1.],\n",
      "          [ 1.,  4., -0.],\n",
      "          [ 1., -0.,  1.]]],\n",
      "\n",
      "\n",
      "        [[[-1.,  1.,  1.],\n",
      "          [-1., -1., -1.],\n",
      "          [-0., -3., -3.]],\n",
      "\n",
      "         [[-1.,  2.,  1.],\n",
      "          [ 0.,  1.,  5.],\n",
      "          [-1.,  0., -0.]],\n",
      "\n",
      "         [[-3.,  0., -2.],\n",
      "          [-1.,  6., -0.],\n",
      "          [-0.,  4.,  2.]],\n",
      "\n",
      "         [[ 3.,  2.,  0.],\n",
      "          [-2., -5., -5.],\n",
      "          [ 0., -2., -0.]],\n",
      "\n",
      "         [[ 3.,  2., -0.],\n",
      "          [ 1.,  6.,  0.],\n",
      "          [-5.,  4., -0.]],\n",
      "\n",
      "         [[ 2.,  1., -0.],\n",
      "          [ 1.,  0.,  1.],\n",
      "          [ 4.,  0., -2.]],\n",
      "\n",
      "         [[ 0., -1.,  3.],\n",
      "          [-0., -6., -4.],\n",
      "          [-1.,  2.,  2.]],\n",
      "\n",
      "         [[ 0.,  2.,  1.],\n",
      "          [ 4.,  2.,  0.],\n",
      "          [ 0.,  0., -3.]]],\n",
      "\n",
      "\n",
      "        [[[-6.,  1., -0.],\n",
      "          [ 3., -2., -2.],\n",
      "          [-0., -2., -2.]],\n",
      "\n",
      "         [[-1.,  0., -0.],\n",
      "          [ 3.,  1., -4.],\n",
      "          [ 2.,  0., -3.]],\n",
      "\n",
      "         [[-3.,  6.,  2.],\n",
      "          [ 2., -7.,  2.],\n",
      "          [ 1., -4., -2.]],\n",
      "\n",
      "         [[-3., -0.,  3.],\n",
      "          [-3., -0.,  3.],\n",
      "          [-2., -1.,  1.]],\n",
      "\n",
      "         [[-7., -3.,  1.],\n",
      "          [ 2.,  1., -1.],\n",
      "          [ 4.,  0.,  0.]],\n",
      "\n",
      "         [[ 1., -3.,  2.],\n",
      "          [-1., -1.,  1.],\n",
      "          [-1.,  2., -1.]],\n",
      "\n",
      "         [[-7.,  6.,  3.],\n",
      "          [-7.,  2.,  1.],\n",
      "          [ 7., -4., -2.]],\n",
      "\n",
      "         [[ 3.,  4., -3.],\n",
      "          [ 2., -1.,  2.],\n",
      "          [-2., -4., -0.]]],\n",
      "\n",
      "\n",
      "        [[[-0.,  1.,  2.],\n",
      "          [ 0., -3., -1.],\n",
      "          [-1., -1.,  0.]],\n",
      "\n",
      "         [[ 2., -0., -1.],\n",
      "          [ 1., -2., -3.],\n",
      "          [ 0.,  1.,  2.]],\n",
      "\n",
      "         [[ 3., -1.,  1.],\n",
      "          [ 3.,  0.,  3.],\n",
      "          [ 1.,  0., -0.]],\n",
      "\n",
      "         [[-2., -1.,  0.],\n",
      "          [ 1.,  1.,  2.],\n",
      "          [ 0.,  1.,  2.]],\n",
      "\n",
      "         [[ 1.,  1.,  2.],\n",
      "          [-2., -5., -1.],\n",
      "          [-1., -1.,  2.]],\n",
      "\n",
      "         [[ 2., -1.,  3.],\n",
      "          [-2., -3., -2.],\n",
      "          [-3., -5., -5.]],\n",
      "\n",
      "         [[-1.,  0., -1.],\n",
      "          [ 2., -3.,  2.],\n",
      "          [ 2.,  2.,  4.]],\n",
      "\n",
      "         [[ 0., -0.,  3.],\n",
      "          [ 1.,  6.,  4.],\n",
      "          [-0.,  4.,  2.]]],\n",
      "\n",
      "\n",
      "        [[[-1.,  0.,  2.],\n",
      "          [ 2.,  3.,  2.],\n",
      "          [-1.,  5.,  0.]],\n",
      "\n",
      "         [[ 1.,  3.,  2.],\n",
      "          [ 0.,  5.,  1.],\n",
      "          [-4.,  1.,  3.]],\n",
      "\n",
      "         [[-0., -1.,  1.],\n",
      "          [ 3.,  1.,  1.],\n",
      "          [-0.,  3.,  1.]],\n",
      "\n",
      "         [[-3., -0.,  2.],\n",
      "          [-3., -0.,  1.],\n",
      "          [-3., -2.,  2.]],\n",
      "\n",
      "         [[ 0., -1., -2.],\n",
      "          [ 0.,  0.,  1.],\n",
      "          [ 1., -1.,  1.]],\n",
      "\n",
      "         [[ 1., -3.,  0.],\n",
      "          [-2.,  4., -0.],\n",
      "          [-2.,  4.,  1.]],\n",
      "\n",
      "         [[-1.,  2., -1.],\n",
      "          [ 3.,  2.,  1.],\n",
      "          [-1.,  1.,  1.]],\n",
      "\n",
      "         [[ 1., -1., -0.],\n",
      "          [-1., -3., -1.],\n",
      "          [-1., -1., -2.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1.,  1.],\n",
      "          [-2., -3., -4.],\n",
      "          [-2., -3.,  1.]],\n",
      "\n",
      "         [[ 0., -0.,  2.],\n",
      "          [-0., -2., -3.],\n",
      "          [ 1., -5., -3.]],\n",
      "\n",
      "         [[ 0., -1., -4.],\n",
      "          [ 6.,  3., -7.],\n",
      "          [ 1.,  1., -1.]],\n",
      "\n",
      "         [[ 1., -2.,  1.],\n",
      "          [ 1., -2.,  1.],\n",
      "          [ 1.,  0., -0.]],\n",
      "\n",
      "         [[-1.,  2.,  2.],\n",
      "          [-5.,  6.,  3.],\n",
      "          [-3.,  5., -1.]],\n",
      "\n",
      "         [[-3.,  0., -0.],\n",
      "          [-1., -1., -0.],\n",
      "          [-2., -5.,  2.]],\n",
      "\n",
      "         [[ 1., -5.,  0.],\n",
      "          [ 3.,  6., -1.],\n",
      "          [ 3.,  7.,  0.]],\n",
      "\n",
      "         [[-1.,  2., -2.],\n",
      "          [-2., -1., -4.],\n",
      "          [-1., -1.,  0.]]],\n",
      "\n",
      "\n",
      "        [[[ 1.,  4.,  1.],\n",
      "          [ 6.,  7.,  6.],\n",
      "          [-4., -2.,  2.]],\n",
      "\n",
      "         [[ 0.,  1., -0.],\n",
      "          [ 3.,  4.,  4.],\n",
      "          [-4., -4., -2.]],\n",
      "\n",
      "         [[-0.,  2., -1.],\n",
      "          [ 2.,  0.,  6.],\n",
      "          [-0., -4., -5.]],\n",
      "\n",
      "         [[ 1., -1., -2.],\n",
      "          [ 1.,  3.,  2.],\n",
      "          [ 0., -1., -4.]],\n",
      "\n",
      "         [[ 3.,  2., -2.],\n",
      "          [-7., -1.,  2.],\n",
      "          [ 2., -1., -4.]],\n",
      "\n",
      "         [[ 0.,  3., -1.],\n",
      "          [ 5., -5., -2.],\n",
      "          [-4.,  4., -2.]],\n",
      "\n",
      "         [[ 0., -4., -1.],\n",
      "          [ 1.,  7.,  6.],\n",
      "          [ 1., -7., -1.]],\n",
      "\n",
      "         [[-1.,  3.,  2.],\n",
      "          [-0., -3., -7.],\n",
      "          [-1.,  3.,  5.]]],\n",
      "\n",
      "\n",
      "        [[[ 0.,  0.,  2.],\n",
      "          [ 2.,  0., -1.],\n",
      "          [ 1.,  1.,  1.]],\n",
      "\n",
      "         [[ 1.,  1., -2.],\n",
      "          [ 1., -0., -2.],\n",
      "          [-1.,  2.,  0.]],\n",
      "\n",
      "         [[-1., -0., -3.],\n",
      "          [-2.,  3., -2.],\n",
      "          [-0., -1., -1.]],\n",
      "\n",
      "         [[-1., -4., -3.],\n",
      "          [-2., -4., -3.],\n",
      "          [-0., -2., -1.]],\n",
      "\n",
      "         [[ 1.,  2., -1.],\n",
      "          [-2.,  7.,  1.],\n",
      "          [ 1.,  1., -1.]],\n",
      "\n",
      "         [[ 1.,  3.,  1.],\n",
      "          [ 0., -6., -2.],\n",
      "          [-1., -4., -4.]],\n",
      "\n",
      "         [[ 4., -0.,  1.],\n",
      "          [ 1.,  5., -2.],\n",
      "          [ 0., -1., -1.]],\n",
      "\n",
      "         [[-1.,  3.,  2.],\n",
      "          [-1.,  3.,  0.],\n",
      "          [-0.,  3.,  3.]]]], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "w_bit = 4\n",
    "weight_q = model.layer1[0].conv2.weight_q # quantized value is stored during the training\n",
    "w_alpha = model.layer1[0].conv2.weight_quant.wgt_alpha\n",
    "w_delta = w_alpha/(2**(w_bit-1)-1)\n",
    "weight_int = weight_q/w_delta\n",
    "print(weight_int) # you should see clean integer numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "interior-oxygen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.,  0.,  0.,  ...,  2.,  2.,  1.],\n",
      "          [ 2.,  1.,  1.,  ...,  0.,  0.,  0.],\n",
      "          [ 1.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          ...,\n",
      "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 1.,  1.,  1.,  ...,  1.,  2.,  1.],\n",
      "          [ 1.,  2.,  2.,  ...,  2.,  2.,  1.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.,  ...,  2.,  2.,  2.],\n",
      "          [ 0.,  1.,  0.,  ...,  0.,  0.,  1.],\n",
      "          [ 0.,  0.,  0.,  ...,  1.,  1.,  2.],\n",
      "          ...,\n",
      "          [ 0.,  0.,  0.,  ...,  1.,  1.,  2.],\n",
      "          [ 0.,  1.,  1.,  ...,  1.,  0.,  2.],\n",
      "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.,  ...,  3.,  2.,  2.],\n",
      "          [ 0.,  0.,  1.,  ...,  2.,  2.,  2.],\n",
      "          [ 0.,  0.,  1.,  ...,  2.,  2.,  2.],\n",
      "          ...,\n",
      "          [ 6.,  2.,  2.,  ...,  2.,  2.,  2.],\n",
      "          [ 7.,  2.,  2.,  ...,  2.,  2.,  1.],\n",
      "          [ 4.,  3.,  2.,  ...,  2.,  2.,  2.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 2.,  3.,  3.,  ...,  0.,  0.,  0.],\n",
      "          [ 1.,  1.,  2.,  ...,  0.,  0.,  0.],\n",
      "          ...,\n",
      "          [ 0.,  0.,  0.,  ...,  1.,  0.,  0.],\n",
      "          [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
      "          [ 0.,  1.,  0.,  ...,  0.,  1.,  0.]],\n",
      "\n",
      "         [[ 2.,  1.,  1.,  ...,  3.,  4.,  4.],\n",
      "          [ 2.,  1.,  1.,  ...,  3.,  4.,  4.],\n",
      "          [ 2.,  1.,  1.,  ...,  3.,  4.,  4.],\n",
      "          ...,\n",
      "          [ 3.,  3.,  2.,  ...,  3.,  4.,  4.],\n",
      "          [ 3.,  4.,  3.,  ...,  3.,  4.,  5.],\n",
      "          [ 4.,  5.,  5.,  ...,  5.,  5.,  5.]],\n",
      "\n",
      "         [[ 3.,  4.,  4.,  ...,  1.,  1.,  1.],\n",
      "          [ 3.,  1.,  2.,  ...,  2.,  0.,  1.],\n",
      "          [ 2.,  2.,  2.,  ...,  1.,  0.,  0.],\n",
      "          ...,\n",
      "          [ 3.,  1.,  1.,  ...,  0.,  0.,  0.],\n",
      "          [ 3.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 2.,  0.,  1.,  ...,  1.,  0.,  1.]]],\n",
      "\n",
      "\n",
      "        [[[ 2.,  2.,  2.,  ...,  2.,  2.,  1.],\n",
      "          [ 1.,  1.,  1.,  ...,  1.,  0.,  0.],\n",
      "          [ 5.,  5.,  5.,  ...,  3.,  0.,  0.],\n",
      "          ...,\n",
      "          [ 1.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  ...,  0.,  1.,  1.],\n",
      "          [ 1.,  1.,  1.,  ...,  0.,  2.,  1.]],\n",
      "\n",
      "         [[ 0.,  3.,  2.,  ...,  2.,  2.,  2.],\n",
      "          [ 0.,  0.,  0.,  ...,  0.,  0.,  3.],\n",
      "          [ 0.,  3.,  4.,  ...,  3.,  3.,  4.],\n",
      "          ...,\n",
      "          [ 0.,  1.,  0.,  ...,  0.,  2.,  2.],\n",
      "          [ 0.,  0.,  0.,  ...,  0.,  0.,  2.],\n",
      "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
      "\n",
      "         [[ 6.,  3.,  3.,  ...,  3.,  2.,  2.],\n",
      "          [ 7.,  2.,  2.,  ...,  2.,  1.,  2.],\n",
      "          [ 1.,  4.,  2.,  ...,  1.,  8.,  1.],\n",
      "          ...,\n",
      "          [ 1.,  1.,  0.,  ...,  0.,  9.,  2.],\n",
      "          [ 0.,  2.,  0.,  ...,  0., 10.,  1.],\n",
      "          [ 2.,  2.,  2.,  ...,  0.,  6.,  3.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          ...,\n",
      "          [ 1.,  1.,  0.,  ...,  1.,  0.,  0.],\n",
      "          [ 2.,  3.,  3.,  ...,  2.,  1.,  1.],\n",
      "          [ 3.,  4.,  3.,  ...,  4.,  0.,  1.]],\n",
      "\n",
      "         [[ 4.,  3.,  3.,  ...,  3.,  4.,  4.],\n",
      "          [ 3.,  4.,  3.,  ...,  3.,  4.,  4.],\n",
      "          [ 9., 10., 10.,  ..., 12.,  5.,  4.],\n",
      "          ...,\n",
      "          [ 2.,  1.,  2.,  ...,  0.,  6.,  5.],\n",
      "          [ 1.,  1.,  0.,  ...,  0.,  5.,  5.],\n",
      "          [ 0.,  1.,  1.,  ...,  0.,  7.,  6.]],\n",
      "\n",
      "         [[ 3.,  1.,  2.,  ...,  2.,  1.,  1.],\n",
      "          [ 3.,  0.,  0.,  ...,  0.,  0.,  1.],\n",
      "          [ 2.,  0.,  0.,  ...,  0.,  0.,  1.],\n",
      "          ...,\n",
      "          [ 2.,  0.,  2.,  ...,  0.,  2.,  0.],\n",
      "          [ 3.,  0.,  1.,  ...,  0.,  2.,  0.],\n",
      "          [ 2.,  1.,  1.,  ...,  2.,  1.,  0.]]],\n",
      "\n",
      "\n",
      "        [[[ 2.,  2.,  2.,  ...,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          ...,\n",
      "          [ 0.,  0.,  0.,  ...,  6.,  4.,  1.],\n",
      "          [ 1.,  1.,  2.,  ...,  0.,  0.,  0.],\n",
      "          [ 1.,  2.,  2.,  ...,  0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  3.,  3.,  ...,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 0.,  1.,  2.,  ...,  0.,  0.,  0.],\n",
      "          ...,\n",
      "          [ 0.,  1.,  1.,  ...,  0.,  0.,  0.],\n",
      "          [ 0.,  1.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
      "\n",
      "         [[ 6.,  3.,  2.,  ...,  2.,  1.,  1.],\n",
      "          [ 5.,  2.,  2.,  ...,  1.,  1.,  1.],\n",
      "          [ 5.,  2.,  2.,  ...,  1.,  1.,  2.],\n",
      "          ...,\n",
      "          [ 5.,  2.,  2.,  ...,  3.,  2.,  0.],\n",
      "          [ 7.,  2.,  2.,  ...,  0.,  0.,  0.],\n",
      "          [ 4.,  3.,  2.,  ...,  0.,  0.,  1.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 1.,  0.,  0.,  ...,  1.,  0.,  1.],\n",
      "          ...,\n",
      "          [ 1.,  0.,  0.,  ...,  1.,  0.,  0.],\n",
      "          [ 1.,  1.,  1.,  ...,  0.,  0.,  2.],\n",
      "          [ 0.,  1.,  0.,  ...,  2.,  1.,  3.]],\n",
      "\n",
      "         [[ 4.,  3.,  4.,  ...,  3.,  3.,  2.],\n",
      "          [ 3.,  3.,  3.,  ...,  3.,  3.,  3.],\n",
      "          [ 3.,  3.,  4.,  ...,  2.,  3.,  2.],\n",
      "          ...,\n",
      "          [ 3.,  3.,  4.,  ...,  5.,  6.,  6.],\n",
      "          [ 3.,  4.,  4.,  ...,  4.,  3.,  1.],\n",
      "          [ 4.,  5.,  5.,  ...,  0.,  0.,  0.]],\n",
      "\n",
      "         [[ 3.,  1.,  1.,  ...,  4.,  4.,  3.],\n",
      "          [ 3.,  1.,  0.,  ...,  3.,  4.,  2.],\n",
      "          [ 3.,  0.,  0.,  ...,  3.,  3.,  2.],\n",
      "          ...,\n",
      "          [ 3.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 3.,  0.,  0.,  ...,  1.,  2.,  2.],\n",
      "          [ 2.,  0.,  0.,  ...,  4.,  4.,  4.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.,  2.,  2.,  ...,  2.,  2.,  1.],\n",
      "          [ 2.,  2.,  2.,  ...,  0.,  0.,  0.],\n",
      "          [ 6.,  6.,  6.,  ...,  0.,  0.,  0.],\n",
      "          ...,\n",
      "          [ 1.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  ...,  0.,  2.,  1.],\n",
      "          [ 0.,  0.,  0.,  ...,  0.,  2.,  1.]],\n",
      "\n",
      "         [[ 0.,  3.,  2.,  ...,  2.,  2.,  2.],\n",
      "          [ 0.,  0.,  0.,  ...,  0.,  1.,  1.],\n",
      "          [ 0.,  2.,  4.,  ...,  3.,  3.,  2.],\n",
      "          ...,\n",
      "          [ 0.,  0.,  0.,  ...,  4.,  2.,  2.],\n",
      "          [ 0.,  0.,  0.,  ...,  3.,  1.,  2.],\n",
      "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
      "\n",
      "         [[ 6.,  3.,  3.,  ...,  3.,  2.,  2.],\n",
      "          [ 7.,  2.,  3.,  ...,  1.,  3.,  2.],\n",
      "          [ 0.,  4.,  3.,  ...,  8.,  1.,  2.],\n",
      "          ...,\n",
      "          [ 0.,  0.,  1.,  ..., 11.,  2.,  2.],\n",
      "          [ 0.,  0.,  1.,  ..., 12.,  2.,  1.],\n",
      "          [ 0.,  0.,  1.,  ...,  5.,  2.,  2.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          ...,\n",
      "          [ 1.,  1.,  2.,  ...,  1.,  0.,  0.],\n",
      "          [ 1.,  2.,  2.,  ...,  1.,  0.,  1.],\n",
      "          [ 3.,  2.,  3.,  ...,  1.,  1.,  0.]],\n",
      "\n",
      "         [[ 4.,  3.,  3.,  ...,  3.,  4.,  4.],\n",
      "          [ 3.,  4.,  4.,  ...,  4.,  4.,  4.],\n",
      "          [10., 11., 12.,  ...,  3.,  4.,  4.],\n",
      "          ...,\n",
      "          [ 2.,  1.,  1.,  ...,  5.,  5.,  4.],\n",
      "          [ 2.,  1.,  1.,  ...,  5.,  5.,  5.],\n",
      "          [ 0.,  0.,  0.,  ...,  4.,  5.,  5.]],\n",
      "\n",
      "         [[ 3.,  1.,  2.,  ...,  2.,  1.,  1.],\n",
      "          [ 3.,  0.,  0.,  ...,  0.,  0.,  1.],\n",
      "          [ 2.,  0.,  0.,  ...,  1.,  1.,  0.],\n",
      "          ...,\n",
      "          [ 2.,  2.,  2.,  ...,  2.,  0.,  0.],\n",
      "          [ 2.,  2.,  2.,  ...,  2.,  0.,  0.],\n",
      "          [ 4.,  4.,  4.,  ...,  2.,  0.,  1.]]],\n",
      "\n",
      "\n",
      "        [[[ 2.,  2.,  2.,  ...,  2.,  2.,  1.],\n",
      "          [ 2.,  2.,  2.,  ...,  0.,  0.,  0.],\n",
      "          [ 6.,  7.,  7.,  ...,  0.,  0.,  0.],\n",
      "          ...,\n",
      "          [ 1.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 1.,  0.,  0.,  ...,  0.,  2.,  1.],\n",
      "          [ 0.,  0.,  0.,  ...,  0.,  2.,  1.]],\n",
      "\n",
      "         [[ 0.,  3.,  2.,  ...,  2.,  2.,  2.],\n",
      "          [ 0.,  0.,  0.,  ...,  0.,  1.,  1.],\n",
      "          [ 0.,  0.,  2.,  ...,  2.,  3.,  2.],\n",
      "          ...,\n",
      "          [ 0.,  0.,  0.,  ...,  4.,  2.,  2.],\n",
      "          [ 0.,  0.,  0.,  ...,  3.,  1.,  2.],\n",
      "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
      "\n",
      "         [[ 6.,  3.,  3.,  ...,  3.,  2.,  2.],\n",
      "          [ 7.,  2.,  3.,  ...,  1.,  3.,  2.],\n",
      "          [ 0.,  4.,  3.,  ...,  8.,  1.,  2.],\n",
      "          ...,\n",
      "          [ 0.,  0.,  0.,  ..., 11.,  2.,  2.],\n",
      "          [ 0.,  0.,  1.,  ..., 12.,  2.,  1.],\n",
      "          [ 0.,  0.,  0.,  ...,  5.,  2.,  2.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 0.,  1.,  0.,  ...,  1.,  0.,  0.],\n",
      "          ...,\n",
      "          [ 2.,  2.,  4.,  ...,  2.,  0.,  0.],\n",
      "          [ 2.,  2.,  2.,  ...,  1.,  0.,  1.],\n",
      "          [ 3.,  2.,  4.,  ...,  1.,  1.,  0.]],\n",
      "\n",
      "         [[ 4.,  3.,  3.,  ...,  3.,  4.,  4.],\n",
      "          [ 3.,  4.,  4.,  ...,  4.,  4.,  4.],\n",
      "          [10., 12., 12.,  ...,  3.,  4.,  4.],\n",
      "          ...,\n",
      "          [ 1.,  0.,  0.,  ...,  6.,  5.,  4.],\n",
      "          [ 2.,  1.,  1.,  ...,  5.,  5.,  5.],\n",
      "          [ 0.,  0.,  0.,  ...,  5.,  5.,  5.]],\n",
      "\n",
      "         [[ 3.,  1.,  2.,  ...,  2.,  1.,  1.],\n",
      "          [ 3.,  0.,  0.,  ...,  0.,  0.,  1.],\n",
      "          [ 2.,  0.,  0.,  ...,  1.,  1.,  0.],\n",
      "          ...,\n",
      "          [ 3.,  1.,  2.,  ...,  2.,  0.,  0.],\n",
      "          [ 2.,  3.,  1.,  ...,  3.,  0.,  0.],\n",
      "          [ 3.,  5.,  5.,  ...,  2.,  0.,  1.]]],\n",
      "\n",
      "\n",
      "        [[[ 2.,  2.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  ...,  1.,  0.,  0.],\n",
      "          [ 0.,  1.,  2.,  ...,  1.,  1.,  0.],\n",
      "          ...,\n",
      "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 1.,  1.,  1.,  ...,  1.,  2.,  1.],\n",
      "          [ 1.,  2.,  2.,  ...,  2.,  2.,  1.]],\n",
      "\n",
      "         [[ 0.,  6.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 0.,  2.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 0.,  3.,  0.,  ...,  0.,  0.,  0.],\n",
      "          ...,\n",
      "          [ 0.,  0.,  0.,  ...,  0.,  0.,  2.],\n",
      "          [ 0.,  1.,  1.,  ...,  1.,  0.,  2.],\n",
      "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
      "\n",
      "         [[ 6.,  6.,  0.,  ...,  2.,  0.,  0.],\n",
      "          [ 6.,  5.,  0.,  ...,  3.,  0.,  0.],\n",
      "          [ 6.,  6.,  0.,  ...,  2.,  2.,  0.],\n",
      "          ...,\n",
      "          [ 5.,  2.,  2.,  ...,  2.,  2.,  2.],\n",
      "          [ 7.,  2.,  2.,  ...,  2.,  2.,  1.],\n",
      "          [ 4.,  3.,  2.,  ...,  2.,  2.,  2.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  ...,  2.,  3.,  2.],\n",
      "          [ 1.,  2.,  1.,  ...,  1.,  1.,  3.],\n",
      "          ...,\n",
      "          [ 1.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
      "          [ 0.,  1.,  0.,  ...,  0.,  1.,  0.]],\n",
      "\n",
      "         [[ 5.,  6.,  1.,  ...,  2.,  3.,  2.],\n",
      "          [ 4.,  7.,  0.,  ...,  4.,  1.,  2.],\n",
      "          [ 4.,  7.,  2.,  ...,  5.,  4.,  1.],\n",
      "          ...,\n",
      "          [ 3.,  3.,  2.,  ...,  3.,  4.,  4.],\n",
      "          [ 3.,  4.,  3.,  ...,  3.,  4.,  5.],\n",
      "          [ 4.,  5.,  5.,  ...,  5.,  5.,  5.]],\n",
      "\n",
      "         [[ 2.,  0.,  1.,  ...,  4.,  4.,  4.],\n",
      "          [ 2.,  1.,  0.,  ...,  2.,  3.,  2.],\n",
      "          [ 2.,  0.,  0.,  ...,  2.,  2.,  1.],\n",
      "          ...,\n",
      "          [ 3.,  0.,  1.,  ...,  1.,  0.,  0.],\n",
      "          [ 3.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 2.,  0.,  1.,  ...,  1.,  0.,  1.]]]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x_bit = 4\n",
    "x = save_output.outputs[2][0]  # input of the 2nd conv layer\n",
    "x_alpha  = model.layer1[0].conv2.act_alpha\n",
    "x_delta = x_alpha/(2**x_bit-1)\n",
    "\n",
    "act_quant_fn = act_quantization(x_bit) # define the quantization function\n",
    "x_q = act_quant_fn(x, x_alpha)         # create the quantized value for x\n",
    "\n",
    "x_int = x_q/x_delta\n",
    "print(x_int) # you should see clean integer numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "ranging-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_int = torch.nn.Conv2d(in_channels = 8, out_channels=8, kernel_size = 3, padding=1, bias = False)\n",
    "conv_int.weight = torch.nn.parameter.Parameter(weight_int)\n",
    "relu = nn.ReLU()\n",
    "bn = nn.BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True).to(device)\n",
    "output_int = conv_int(x_int)\n",
    "output_int1 = output_int*w_delta*x_delta+save_output.outputs[1][0]\n",
    "output_recovered = relu(output_int1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "8d5639a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.4393e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "difference = abs(save_output.outputs[3][0] - output_recovered )\n",
    "print(difference.mean())  ## It should be small, e.g.,2.3 in my trainned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "8735f8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 8, 32, 32])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_int.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "52622a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 32, 32])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 2.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [4., 4., 4., 3., 3., 3., 4., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 2., 1., 2., 0.],\n",
      "        [4., 4., 4., 4., 4., 5., 3., 5.]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "X_pad = x_int[0]\n",
    "print(X_pad.size())\n",
    "x_test = X_pad[:,0,1:9]\n",
    "print(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "148da9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pad = torch.zeros(128, 8, 34, 34).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "b4978f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 8, 3, 10])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pad[ : ,  :, 1:33, 1:33] = x_int.cuda()\n",
    "x_new= x_pad[:,:,0:3,0:10]\n",
    "x_new.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "b83f543a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x_new[0]\n",
    "X = torch.reshape(X, (X.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "c29f24bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 30])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "f0a08ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_precision = 4\n",
    "file = open('./resnet_out/activation.txt', 'w') #write to file\n",
    "file.write('#time0row7[msb-lsb],time0row6[msb-lst],....,time0row0[msb-lst]#\\n')\n",
    "file.write('#time1row7[msb-lsb],time1row6[msb-lst],....,time1row0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for i in range(X.size(1)):  # time step\n",
    "    for j in range(X.size(0)): # row #\n",
    "        X_bin = '{0:04b}'.format(int(X[7-j,i].item()+0.001))\n",
    "        for k in range(bit_precision):\n",
    "            file.write(X_bin[k])        \n",
    "        #file.write(' ')  # for visibility with blank between words, you can use\n",
    "    file.write('\\n')\n",
    "file.close() #close file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "9bd7aed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "de54d2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8, 3, 3])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_int.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "a0d85ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8, 9])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_int.size() # 8, 8 , 3, 3\n",
    "W = torch.reshape(weight_int, (weight_int.size(0), weight_int.size(1), -1))\n",
    "W.size() # 8, 8, 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "edb9963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_precision = 4\n",
    "#file = open('weight.txt', 'w') #write to file\n",
    "#file.write('#col0row7[msb-lsb],col0row6[msb-lst],....,col0row0[msb-lst]#\\n')\n",
    "#file.write('#col1row7[msb-lsb],col1row6[msb-lst],....,col1row0[msb-lst]#\\n')\n",
    "#file.write('#................#\\n')\n",
    "for kij in range(9):\n",
    "    file = open('./resnet_out/w{}.txt'.format(str(kij)), 'w')\n",
    "    file.write('#col0row7[msb-lsb],col0row6[msb-lst],....,col0row0[msb-lst]#\\n')\n",
    "    file.write('#col1row7[msb-lsb],col1row6[msb-lst],....,col1row0[msb-lst]#\\n')\n",
    "    file.write('#................#\\n')\n",
    "    for i in range(W.size(0)):  \n",
    "        for j in range(W.size(1)):\n",
    "            if (W[i, 7-j, kij].item()<0):\n",
    "                W_bin = '{0:04b}'.format(int(W[i,7-j,kij].item()+2**bit_precision+0.001))\n",
    "            else:\n",
    "                W_bin = '{0:04b}'.format(int(W[i,7-j,kij].item()+0.001))\n",
    "            for k in range(bit_precision):\n",
    "                file.write(W_bin[k])        \n",
    "            #file.write(' ')  # for visibility with blank between words, you can use\n",
    "        file.write('\\n')\n",
    "    file.close() #close file  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "860e1680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  2., -5.,  0., -2.,  1.,  1.,  2.], device='cuda:0',\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[0,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "73f75dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 8, 32, 32])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_int.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "544b65fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1024])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = output_int[0]\n",
    "out.size()\n",
    "out = torch.reshape(out, (out.size(0), -1))\n",
    "print(out.size())\n",
    "out = out [:,0:8]\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "28c54347",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_precision = 16\n",
    "file = open('./resnet_out/output.txt', 'w') #write to file\n",
    "file.write('#time0col7[msb-lsb],time0col6[msb-lst],....,time0col0[msb-lst]#\\n')\n",
    "file.write('#time1col7[msb-lsb],time1col6[msb-lst],....,time1col0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for i in range(out.size(1)):\n",
    "    for j in range(out.size(0)):\n",
    "        if (out[7-j,i].item()<0):\n",
    "            O_bin = '{0:016b}'.format(int(out[7-j,i].item()+2**bit_precision+0.001))\n",
    "        else:\n",
    "            O_bin = '{0:016b}'.format(int(out[7-j,i].item()+0.001))\n",
    "        for k in range(bit_precision):\n",
    "            file.write(O_bin[k])\n",
    "        #file.write(' ')  # for visibility with blank between words, you can use\n",
    "    file.write('\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "7936c8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-60.,  -4.,  -2.,   0.,  13., -13.,  -7.,   9.],\n",
       "        [  8.,  37.,  46.,  50.,  38.,  42.,  35.,  21.],\n",
       "        [-19.,   2.,   5.,   5.,   7.,   7., -22.,  27.],\n",
       "        [  0.,  -7.,  -8.,  -5.,  -1.,  21.,  -4., -16.],\n",
       "        [ 19.,   2.,  -2.,  -5.,  -4.,   5.,   1.,  20.],\n",
       "        [ 32., -16., -15., -16., -21., -26.,  16., -74.],\n",
       "        [-21., -76., -70., -67., -55., -62., -70., -59.],\n",
       "        [ 47.,  22.,  19.,  18.,   9.,  15.,   4.,  -3.]], device='cuda:0',\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "corresponding-significance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[49.0000, 35.0000, 35.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [14.0000, 14.0000, 14.0000,  ..., 21.0000, 21.0000,  0.0000],\n",
      "          [14.0000, 14.0000, 14.0000,  ..., 21.0000, 21.0000,  0.0000],\n",
      "          ...,\n",
      "          [21.0000, 21.0000, 21.0000,  ..., 21.0000, 21.0000,  0.0000],\n",
      "          [21.0000, 21.0000, 21.0000,  ..., 21.0000, 21.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  ..., 28.0000, 28.0000, 28.0000],\n",
      "          [ 0.0000,  7.0000,  7.0000,  ...,  7.0000,  7.0000, 14.0000],\n",
      "          [ 0.0000,  7.0000,  7.0000,  ...,  7.0000,  7.0000, 14.0000],\n",
      "          ...,\n",
      "          [21.0000,  7.0000,  7.0000,  ...,  7.0000,  7.0000, 14.0000],\n",
      "          [21.0000,  7.0000,  7.0000,  ...,  7.0000,  7.0000, 14.0000],\n",
      "          [14.0000,  7.0000,  7.0000,  ...,  7.0000,  7.0000,  7.0000]],\n",
      "\n",
      "         [[49.0000, 14.0000, 14.0000,  ..., 14.0000, 14.0000, 49.0000],\n",
      "          [49.0000,  7.0000,  7.0000,  ..., 14.0000, 14.0000, 49.0000],\n",
      "          [49.0000,  7.0000,  7.0000,  ..., 14.0000, 14.0000, 49.0000],\n",
      "          ...,\n",
      "          [ 0.0000, 14.0000, 14.0000,  ..., 14.0000, 14.0000, 49.0000],\n",
      "          [ 0.0000, 14.0000, 14.0000,  ..., 14.0000, 14.0000, 49.0000],\n",
      "          [ 0.0000, 21.0000, 21.0000,  ..., 21.0000, 21.0000, 49.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[77.0000, 14.0000, 14.0000,  ..., 35.0000, 35.0000,  0.0000],\n",
      "          [70.0000, 21.0000, 21.0000,  ..., 21.0000, 21.0000,  0.0000],\n",
      "          [70.0000, 21.0000, 21.0000,  ..., 21.0000, 21.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000, 21.0000, 21.0000,  ..., 21.0000, 21.0000,  0.0000],\n",
      "          [ 0.0000, 21.0000, 21.0000,  ..., 21.0000, 21.0000,  0.0000],\n",
      "          [ 0.0000, 28.0000, 28.0000,  ..., 28.0000, 28.0000,  0.0000]],\n",
      "\n",
      "         [[42.0000, 35.0000, 35.0000,  ...,  0.0000,  0.0000,  7.0000],\n",
      "          [14.0000, 14.0000, 14.0000,  ...,  0.0000,  0.0000, 14.0000],\n",
      "          [14.0000, 14.0000, 14.0000,  ...,  0.0000,  0.0000, 14.0000],\n",
      "          ...,\n",
      "          [ 7.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 14.0000],\n",
      "          [ 7.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 14.0000],\n",
      "          [14.0000, 14.0000, 14.0000,  ..., 14.0000, 14.0000, 28.0000]],\n",
      "\n",
      "         [[ 7.0000, 21.0000, 21.0000,  ...,  7.0000,  7.0000,  0.0000],\n",
      "          [ 0.0000,  7.0000,  7.0000,  ..., 21.0000, 21.0000,  7.0000],\n",
      "          [ 0.0000,  7.0000,  7.0000,  ..., 21.0000, 21.0000,  7.0000],\n",
      "          ...,\n",
      "          [35.0000, 21.0000, 21.0000,  ..., 21.0000, 21.0000,  7.0000],\n",
      "          [35.0000, 21.0000, 21.0000,  ..., 21.0000, 21.0000,  7.0000],\n",
      "          [42.0000, 35.0000, 35.0000,  ..., 35.0000, 35.0000, 21.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [21.0000, 21.0000, 21.0000,  ..., 21.0000, 21.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, 28.0000,  0.0000],\n",
      "          ...,\n",
      "          [14.0000, 21.0000, 21.0000,  ..., 28.0000, 14.0000,  0.0000],\n",
      "          [21.0000, 21.0000, 21.0000,  ..., 28.0000, 14.0000,  0.0000],\n",
      "          [14.0000, 14.0000, 14.0000,  ...,  7.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[35.0000, 28.0000, 28.0000,  ..., 28.0000, 28.0000, 28.0000],\n",
      "          [21.0000,  7.0000,  7.0000,  ...,  7.0000,  7.0000, 14.0000],\n",
      "          [14.0000,  7.0000,  7.0000,  ...,  7.0000, 21.0000, 14.0000],\n",
      "          ...,\n",
      "          [14.0000, 14.0000,  7.0000,  ..., 14.0000, 28.0000, 14.0000],\n",
      "          [14.0000, 14.0000, 14.0000,  ..., 14.0000, 28.0000, 14.0000],\n",
      "          [14.0000, 14.0000, 14.0000,  ...,  7.0000, 14.0000,  7.0000]],\n",
      "\n",
      "         [[ 0.0000, 14.0000, 14.0000,  ..., 14.0000, 14.0000, 49.0000],\n",
      "          [ 0.0000, 14.0000, 14.0000,  ..., 14.0000, 14.0000, 49.0000],\n",
      "          [ 0.0000, 28.0000, 28.0000,  ..., 14.0000, 21.0000, 49.0000],\n",
      "          ...,\n",
      "          [ 7.0000, 14.0000, 21.0000,  ...,  0.0000,  0.0000, 49.0000],\n",
      "          [14.0000, 14.0000, 21.0000,  ...,  0.0000,  0.0000, 49.0000],\n",
      "          [14.0000, 14.0000, 14.0000,  ...,  0.0000,  0.0000, 49.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000, 35.0000, 35.0000,  ..., 35.0000, 35.0000,  0.0000],\n",
      "          [ 0.0000, 21.0000, 21.0000,  ..., 21.0000, 21.0000,  0.0000],\n",
      "          [ 0.0000, 35.0000, 35.0000,  ..., 28.0000, 28.0000,  0.0000],\n",
      "          ...,\n",
      "          [14.0000, 28.0000, 28.0000,  ..., 56.0000,  0.0000,  0.0000],\n",
      "          [21.0000, 21.0000, 28.0000,  ..., 56.0000,  0.0000,  0.0000],\n",
      "          [21.0000, 14.0000, 14.0000,  ..., 63.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  7.0000],\n",
      "          [ 7.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 14.0000],\n",
      "          [21.0000, 21.0000, 21.0000,  ..., 14.0000,  0.0000, 14.0000],\n",
      "          ...,\n",
      "          [21.0000, 14.0000, 21.0000,  ...,  0.0000,  0.0000, 14.0000],\n",
      "          [28.0000, 14.0000, 14.0000,  ...,  0.0000,  0.0000, 14.0000],\n",
      "          [21.0000,  7.0000,  7.0000,  ...,  0.0000,  7.0000, 28.0000]],\n",
      "\n",
      "         [[21.0000,  7.0000,  7.0000,  ...,  7.0000,  7.0000,  0.0000],\n",
      "          [35.0000, 21.0000, 21.0000,  ..., 21.0000, 21.0000,  7.0000],\n",
      "          [42.0000, 42.0000, 42.0000,  ..., 42.0000, 35.0000,  7.0000],\n",
      "          ...,\n",
      "          [14.0000, 14.0000, 21.0000,  ..., 28.0000, 35.0000,  7.0000],\n",
      "          [14.0000, 14.0000, 14.0000,  ..., 28.0000, 35.0000,  7.0000],\n",
      "          [14.0000,  7.0000,  7.0000,  ..., 21.0000, 42.0000, 21.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ..., 14.0000, 14.0000, 14.0000],\n",
      "          [21.0000, 21.0000, 21.0000,  ..., 21.0000, 21.0000, 14.0000],\n",
      "          [21.0000, 21.0000, 21.0000,  ..., 21.0000, 21.0000, 14.0000],\n",
      "          ...,\n",
      "          [21.0000, 21.0000, 21.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [21.0000, 21.0000, 21.0000,  ..., 14.0000, 21.0000, 21.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ..., 28.0000, 28.0000, 21.0000]],\n",
      "\n",
      "         [[35.0000, 28.0000, 28.0000,  ...,  7.0000,  7.0000,  7.0000],\n",
      "          [21.0000,  7.0000,  7.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [21.0000,  7.0000,  7.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [21.0000,  7.0000,  7.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [21.0000,  7.0000,  7.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [14.0000,  7.0000,  7.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000, 14.0000, 14.0000,  ..., 14.0000, 14.0000, 14.0000],\n",
      "          [ 0.0000, 14.0000, 14.0000,  ..., 14.0000, 14.0000, 21.0000],\n",
      "          [ 0.0000, 14.0000, 14.0000,  ..., 14.0000, 14.0000, 21.0000],\n",
      "          ...,\n",
      "          [ 0.0000, 14.0000, 14.0000,  ..., 21.0000, 21.0000, 35.0000],\n",
      "          [ 0.0000, 14.0000, 14.0000,  ..., 21.0000, 21.0000, 14.0000],\n",
      "          [ 0.0000, 21.0000, 21.0000,  ..., 14.0000, 14.0000,  7.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000, 35.0000, 35.0000,  ..., 14.0000, 21.0000,  7.0000],\n",
      "          [ 0.0000, 21.0000, 21.0000,  ..., 28.0000, 21.0000, 14.0000],\n",
      "          [ 0.0000, 21.0000, 21.0000,  ..., 28.0000, 21.0000, 14.0000],\n",
      "          ...,\n",
      "          [ 0.0000, 21.0000, 21.0000,  ..., 28.0000, 21.0000, 21.0000],\n",
      "          [ 0.0000, 21.0000, 21.0000,  ..., 14.0000, 14.0000, 28.0000],\n",
      "          [ 0.0000, 28.0000, 28.0000,  ..., 28.0000, 28.0000, 28.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 14.0000],\n",
      "          [ 7.0000,  0.0000,  0.0000,  ...,  7.0000,  7.0000, 21.0000],\n",
      "          [ 7.0000,  0.0000,  0.0000,  ...,  7.0000,  7.0000, 21.0000],\n",
      "          ...,\n",
      "          [ 7.0000,  0.0000,  0.0000,  ...,  7.0000, 14.0000, 28.0000],\n",
      "          [ 7.0000,  0.0000,  0.0000,  ..., 21.0000, 21.0000, 14.0000],\n",
      "          [14.0000, 14.0000, 14.0000,  ..., 14.0000,  7.0000,  7.0000]],\n",
      "\n",
      "         [[21.0000,  7.0000,  7.0000,  ..., 14.0000, 14.0000,  7.0000],\n",
      "          [35.0000, 21.0000, 21.0000,  ..., 14.0000, 14.0000, 14.0000],\n",
      "          [35.0000, 21.0000, 21.0000,  ..., 14.0000, 14.0000, 14.0000],\n",
      "          ...,\n",
      "          [35.0000, 21.0000, 21.0000,  ..., 21.0000, 21.0000, 21.0000],\n",
      "          [35.0000, 21.0000, 21.0000,  ..., 28.0000, 21.0000, 21.0000],\n",
      "          [42.0000, 35.0000, 35.0000,  ..., 14.0000, 14.0000, 14.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [21.0000, 21.0000, 21.0000,  ..., 21.0000, 21.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ..., 35.0000, 21.0000,  0.0000],\n",
      "          ...,\n",
      "          [21.0000, 14.0000, 14.0000,  ..., 14.0000, 21.0000,  0.0000],\n",
      "          [21.0000, 14.0000, 14.0000,  ..., 14.0000, 21.0000,  0.0000],\n",
      "          [84.0000, 77.0000, 77.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[35.0000, 28.0000, 28.0000,  ..., 28.0000, 28.0000, 28.0000],\n",
      "          [21.0000,  7.0000,  7.0000,  ...,  7.0000,  7.0000, 14.0000],\n",
      "          [ 7.0000,  7.0000,  7.0000,  ..., 21.0000,  7.0000, 14.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  7.0000,  7.0000,  ..., 35.0000,  7.0000, 14.0000],\n",
      "          [ 0.0000,  7.0000,  7.0000,  ..., 35.0000,  7.0000, 14.0000],\n",
      "          [ 0.0000,  7.0000,  7.0000,  ..., 21.0000,  7.0000,  7.0000]],\n",
      "\n",
      "         [[ 0.0000, 14.0000, 14.0000,  ..., 14.0000, 14.0000, 49.0000],\n",
      "          [ 0.0000, 14.0000, 14.0000,  ..., 14.0000, 14.0000, 49.0000],\n",
      "          [ 0.0000, 28.0000, 28.0000,  ..., 21.0000, 14.0000, 49.0000],\n",
      "          ...,\n",
      "          [49.0000,  7.0000,  7.0000,  ...,  0.0000, 14.0000, 49.0000],\n",
      "          [49.0000, 14.0000, 14.0000,  ...,  0.0000, 14.0000, 49.0000],\n",
      "          [42.0000,  7.0000,  0.0000,  ...,  0.0000, 21.0000, 49.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000, 35.0000, 35.0000,  ..., 35.0000, 35.0000,  0.0000],\n",
      "          [ 0.0000, 21.0000, 21.0000,  ..., 21.0000, 21.0000,  0.0000],\n",
      "          [ 0.0000, 35.0000, 42.0000,  ..., 35.0000, 21.0000,  0.0000],\n",
      "          ...,\n",
      "          [70.0000, 21.0000, 21.0000,  ...,  0.0000, 21.0000,  0.0000],\n",
      "          [70.0000, 21.0000, 21.0000,  ...,  0.0000, 21.0000,  0.0000],\n",
      "          [63.0000, 14.0000, 14.0000,  ...,  0.0000, 28.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  7.0000],\n",
      "          [ 7.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 14.0000],\n",
      "          [28.0000, 21.0000, 21.0000,  ...,  0.0000,  0.0000, 14.0000],\n",
      "          ...,\n",
      "          [21.0000, 14.0000, 14.0000,  ...,  0.0000,  0.0000, 14.0000],\n",
      "          [21.0000, 14.0000, 14.0000,  ...,  0.0000,  0.0000, 14.0000],\n",
      "          [ 7.0000,  7.0000,  7.0000,  ...,  7.0000, 14.0000, 28.0000]],\n",
      "\n",
      "         [[21.0000,  7.0000,  7.0000,  ...,  7.0000,  7.0000,  0.0000],\n",
      "          [35.0000, 21.0000, 21.0000,  ..., 21.0000, 21.0000,  7.0000],\n",
      "          [49.0000, 49.0000, 49.0000,  ..., 42.0000, 21.0000,  7.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  7.0000,  7.0000,  ..., 56.0000, 21.0000,  7.0000],\n",
      "          [ 0.0000,  7.0000,  7.0000,  ..., 56.0000, 21.0000,  7.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ..., 49.0000, 35.0000, 21.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [21.0000, 21.0000, 21.0000,  ..., 21.0000, 21.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ..., 35.0000, 21.0000,  0.0000],\n",
      "          ...,\n",
      "          [21.0000, 21.0000, 28.0000,  ..., 14.0000, 21.0000,  0.0000],\n",
      "          [21.0000, 14.0000, 21.0000,  ..., 14.0000, 21.0000,  0.0000],\n",
      "          [91.0000, 84.0000, 84.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[35.0000, 28.0000, 28.0000,  ..., 28.0000, 28.0000, 28.0000],\n",
      "          [21.0000,  7.0000,  7.0000,  ...,  7.0000,  7.0000, 14.0000],\n",
      "          [ 7.0000,  7.0000,  7.0000,  ..., 21.0000,  7.0000, 14.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ..., 35.0000,  7.0000, 14.0000],\n",
      "          [ 0.0000,  7.0000,  0.0000,  ..., 35.0000,  7.0000, 14.0000],\n",
      "          [ 0.0000,  7.0000,  7.0000,  ..., 21.0000,  7.0000,  7.0000]],\n",
      "\n",
      "         [[ 0.0000, 14.0000, 14.0000,  ..., 14.0000, 14.0000, 49.0000],\n",
      "          [ 0.0000, 14.0000, 14.0000,  ..., 14.0000, 14.0000, 49.0000],\n",
      "          [ 0.0000, 28.0000, 28.0000,  ..., 14.0000, 14.0000, 49.0000],\n",
      "          ...,\n",
      "          [49.0000,  7.0000,  0.0000,  ...,  0.0000, 14.0000, 49.0000],\n",
      "          [49.0000,  7.0000,  7.0000,  ...,  0.0000, 14.0000, 49.0000],\n",
      "          [42.0000,  0.0000,  0.0000,  ...,  0.0000, 21.0000, 49.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000, 35.0000, 35.0000,  ..., 35.0000, 35.0000,  0.0000],\n",
      "          [ 0.0000, 21.0000, 21.0000,  ..., 21.0000, 21.0000,  0.0000],\n",
      "          [ 0.0000, 35.0000, 35.0000,  ..., 28.0000, 21.0000,  0.0000],\n",
      "          ...,\n",
      "          [70.0000, 21.0000, 42.0000,  ...,  0.0000, 21.0000,  0.0000],\n",
      "          [77.0000, 21.0000, 14.0000,  ...,  0.0000, 21.0000,  0.0000],\n",
      "          [70.0000, 14.0000, 21.0000,  ...,  0.0000, 28.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  7.0000],\n",
      "          [ 7.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 14.0000],\n",
      "          [21.0000, 21.0000, 21.0000,  ...,  7.0000,  0.0000, 14.0000],\n",
      "          ...,\n",
      "          [14.0000, 21.0000, 21.0000,  ...,  7.0000,  0.0000, 14.0000],\n",
      "          [14.0000, 14.0000, 21.0000,  ...,  7.0000,  0.0000, 14.0000],\n",
      "          [ 7.0000,  7.0000,  7.0000,  ..., 14.0000, 14.0000, 28.0000]],\n",
      "\n",
      "         [[21.0000,  7.0000,  7.0000,  ...,  7.0000,  7.0000,  0.0000],\n",
      "          [35.0000, 21.0000, 21.0000,  ..., 21.0000, 21.0000,  7.0000],\n",
      "          [49.0000, 49.0000, 49.0000,  ..., 42.0000, 21.0000,  7.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  7.0000, 21.0000,  ..., 56.0000, 21.0000,  7.0000],\n",
      "          [ 0.0000,  7.0000,  7.0000,  ..., 56.0000, 21.0000,  7.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ..., 49.0000, 35.0000, 21.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000, 21.0000,  ..., 14.0000, 14.0000, 21.0000],\n",
      "          [21.0000,  0.0000, 28.0000,  ..., 21.0000, 21.0000, 21.0000],\n",
      "          [21.0000,  0.0000, 14.0000,  ...,  7.0000, 21.0000, 28.0000],\n",
      "          ...,\n",
      "          [21.0000, 21.0000, 21.0000,  ..., 21.0000, 21.0000,  0.0000],\n",
      "          [21.0000, 21.0000, 21.0000,  ..., 21.0000, 21.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[35.0000, 28.0000,  0.0000,  ...,  7.0000,  0.0000,  0.0000],\n",
      "          [21.0000, 14.0000,  0.0000,  ...,  7.0000,  0.0000,  0.0000],\n",
      "          [21.0000, 14.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [21.0000,  7.0000,  7.0000,  ...,  7.0000,  7.0000, 14.0000],\n",
      "          [21.0000,  7.0000,  7.0000,  ...,  7.0000,  7.0000, 14.0000],\n",
      "          [14.0000,  7.0000,  7.0000,  ...,  7.0000,  7.0000,  7.0000]],\n",
      "\n",
      "         [[ 0.0000, 49.0000, 49.0000,  ..., 14.0000, 14.0000, 14.0000],\n",
      "          [ 0.0000, 49.0000, 49.0000,  ..., 14.0000, 21.0000,  7.0000],\n",
      "          [ 0.0000, 49.0000, 49.0000,  ...,  7.0000, 14.0000, 14.0000],\n",
      "          ...,\n",
      "          [ 0.0000, 14.0000, 14.0000,  ..., 14.0000, 14.0000, 49.0000],\n",
      "          [ 0.0000, 14.0000, 14.0000,  ..., 14.0000, 14.0000, 49.0000],\n",
      "          [ 0.0000, 21.0000, 21.0000,  ..., 21.0000, 21.0000, 49.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0000, 91.0000,  ..., 21.0000, 28.0000, 28.0000],\n",
      "          [ 0.0000,  0.0000, 77.0000,  ..., 14.0000, 28.0000, 21.0000],\n",
      "          [ 0.0000,  0.0000, 70.0000,  ...,  7.0000, 14.0000, 28.0000],\n",
      "          ...,\n",
      "          [ 0.0000, 21.0000, 21.0000,  ..., 21.0000, 21.0000,  0.0000],\n",
      "          [ 0.0000, 21.0000, 21.0000,  ..., 21.0000, 21.0000,  0.0000],\n",
      "          [ 0.0000, 28.0000, 28.0000,  ..., 28.0000, 28.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  7.0000,  7.0000,  ...,  7.0000,  7.0000,  7.0000],\n",
      "          [ 7.0000, 14.0000,  0.0000,  ...,  7.0000,  7.0000,  7.0000],\n",
      "          [ 7.0000,  7.0000,  0.0000,  ...,  7.0000,  7.0000, 14.0000],\n",
      "          ...,\n",
      "          [ 7.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 14.0000],\n",
      "          [ 7.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 14.0000],\n",
      "          [14.0000, 14.0000, 14.0000,  ..., 14.0000, 14.0000, 28.0000]],\n",
      "\n",
      "         [[21.0000,  0.0000,  0.0000,  ..., 14.0000, 14.0000, 14.0000],\n",
      "          [35.0000,  7.0000,  0.0000,  ..., 14.0000, 14.0000, 14.0000],\n",
      "          [35.0000,  7.0000,  0.0000,  ..., 21.0000, 14.0000, 14.0000],\n",
      "          ...,\n",
      "          [35.0000, 21.0000, 21.0000,  ..., 21.0000, 21.0000,  7.0000],\n",
      "          [35.0000, 21.0000, 21.0000,  ..., 21.0000, 21.0000,  7.0000],\n",
      "          [42.0000, 35.0000, 35.0000,  ..., 35.0000, 35.0000, 21.0000]]]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x_bit = 4\n",
    "x0 = save_output.outputs[1][0]  # input of the 2nd conv layer\n",
    "x0_alpha  = model.layer1[0].conv2.act_alpha\n",
    "x0_delta = x0_alpha/(2**x_bit-1)\n",
    "\n",
    "act_quant_fn = act_quantization(x_bit) # define the quantization function\n",
    "x0_q = act_quant_fn(x0, x0_alpha*w_alpha)         # create the quantized value for x\n",
    "\n",
    "x0_int = x0_q/x0_delta/w_delta\n",
    "print(x0_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "exposed-witch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ -60.,   -4.,   -2.,  ...,   -9.,  -31.,  -65.],\n",
      "          [ -45.,  -34.,  -26.,  ...,  -24.,  -63.,  -84.],\n",
      "          [ -48.,   -1.,   -6.,  ...,  -34.,  -64.,  -97.],\n",
      "          ...,\n",
      "          [  -8.,  -66.,  -24.,  ...,  -14.,  -66.,  -95.],\n",
      "          [  10.,  -47.,  -19.,  ...,  -15.,  -60.,  -94.],\n",
      "          [  18.,   -8.,   13.,  ...,    1.,  -26.,  -71.]],\n",
      "\n",
      "         [[   8.,   37.,   46.,  ...,    9.,    4.,   35.],\n",
      "          [  19.,   45.,   47.,  ...,   29.,   42.,   55.],\n",
      "          [  20.,   25.,   48.,  ...,   27.,   28.,   49.],\n",
      "          ...,\n",
      "          [  92.,   47.,   45.,  ...,   19.,   17.,   52.],\n",
      "          [  64.,    6.,    7.,  ...,  -16.,    0.,   37.],\n",
      "          [   3.,  -31.,  -25.,  ...,  -20.,  -14.,   27.]],\n",
      "\n",
      "         [[ -19.,    2.,    5.,  ...,  -19.,  -23.,   -5.],\n",
      "          [ -21.,  -33.,  -28.,  ...,  -15.,  -33.,  -43.],\n",
      "          [  15.,   -5.,  -11.,  ...,  -23.,  -21.,  -28.],\n",
      "          ...,\n",
      "          [  20.,  -19.,  -40.,  ...,    9.,  -15.,  -43.],\n",
      "          [ -38.,  -31.,  -41.,  ...,  -13.,  -14.,  -35.],\n",
      "          [  72.,  -12.,  -26.,  ...,   -5.,   -1.,  -56.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[  32.,  -16.,  -15.,  ...,   48.,   52.,  113.],\n",
      "          [  12.,  -10.,  -10.,  ...,   40.,   49.,  114.],\n",
      "          [  30.,  -19.,  -33.,  ...,   39.,   56.,  118.],\n",
      "          ...,\n",
      "          [  19.,   38.,    2.,  ...,   29.,   55.,  106.],\n",
      "          [  24.,   73.,   42.,  ...,   45.,   55.,  123.],\n",
      "          [ -11.,   14.,   10.,  ...,    9.,   27.,   60.]],\n",
      "\n",
      "         [[ -21.,  -76.,  -70.,  ...,   77.,   52.,   16.],\n",
      "          [  15.,   39.,   28.,  ...,  -20.,  -19.,  -13.],\n",
      "          [  11.,    1.,  -25.,  ...,   17.,   -9.,   -8.],\n",
      "          ...,\n",
      "          [   5.,    1.,    4.,  ...,   14.,   -8.,  -19.],\n",
      "          [  -1.,   32.,   19.,  ...,   17.,   18.,   16.],\n",
      "          [ 100.,   95.,  108.,  ...,   99.,   89.,   50.]],\n",
      "\n",
      "         [[  47.,   22.,   19.,  ...,    4.,    8.,   60.],\n",
      "          [  23.,   24.,   21.,  ...,   18.,   15.,   92.],\n",
      "          [  44.,   37.,   22.,  ...,   16.,   14.,   90.],\n",
      "          ...,\n",
      "          [  37.,    9.,   24.,  ...,   -4.,   -2.,   85.],\n",
      "          [  21.,   -2.,   14.,  ...,   -1.,    1.,   84.],\n",
      "          [  37.,   29.,   52.,  ...,   47.,   40.,  105.]]],\n",
      "\n",
      "\n",
      "        [[[   3.,  -23.,    3.,  ...,   -3.,  -39.,  -65.],\n",
      "          [ -28.,  -82.,  -82.,  ...,  -67.,  -76., -116.],\n",
      "          [  23.,  -13.,   -4.,  ...,  -19.,  -89., -126.],\n",
      "          ...,\n",
      "          [  -7.,  -17.,  -66.,  ...,  156.,  -72., -152.],\n",
      "          [ -23.,  -61.,  -29.,  ...,  147.,  -49., -125.],\n",
      "          [  -6.,  -11.,  -31.,  ...,  145.,  -43.,  -96.]],\n",
      "\n",
      "         [[  58.,   17.,    3.,  ...,    5.,    5.,   35.],\n",
      "          [  53.,   15.,   10.,  ...,   30.,   46.,   44.],\n",
      "          [ -87., -127., -136.,  ...,  -83.,  112.,   57.],\n",
      "          ...,\n",
      "          [  26.,   42.,   26.,  ...,   17.,  118.,   20.],\n",
      "          [  24.,   73.,   47.,  ...,    7.,  130.,   10.],\n",
      "          [  36.,   52.,   53.,  ...,   -8.,   27.,   -1.]],\n",
      "\n",
      "         [[-109.,  -24.,  -10.,  ...,  -13.,  -27.,   -8.],\n",
      "          [ -57.,  -70.,  -63.,  ...,  -43.,  -10.,  -27.],\n",
      "          [  79.,  -62.,  -52.,  ...,  -46., -235.,    2.],\n",
      "          ...,\n",
      "          [  -4.,   47.,   74.,  ...,   15.,  -28.,  -57.],\n",
      "          [  10.,  -43.,  -21.,  ...,   23.,  -46.,  -35.],\n",
      "          [   9.,   -4.,  -36.,  ...,   13.,   91.,  -89.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[  34.,   57.,   25.,  ...,   37.,   47.,  103.],\n",
      "          [  41.,   84.,   66.,  ...,   97.,   75.,  102.],\n",
      "          [ -39.,  -28.,    2.,  ...,  -27.,   84.,  164.],\n",
      "          ...,\n",
      "          [  14.,   -9.,  -13.,  ..., -150.,   66.,  158.],\n",
      "          [  -1.,   -3.,   -7.,  ..., -165.,   72.,  168.],\n",
      "          [  -1.,   -8.,    1.,  ..., -123.,   20.,   86.]],\n",
      "\n",
      "         [[  38.,   56.,   57.,  ...,   62.,   48.,    8.],\n",
      "          [ -45.,  -60.,  -74.,  ..., -137.,  -40.,  -12.],\n",
      "          [ 248.,  293.,  315.,  ...,  245.,  -32.,  -14.],\n",
      "          ...,\n",
      "          [  27.,  -11.,  -21.,  ...,   15.,   -6.,    6.],\n",
      "          [ -12.,  -56.,  -51.,  ...,   51.,  -48.,   15.],\n",
      "          [   2.,   29.,   23.,  ...,   54.,  147.,   54.]],\n",
      "\n",
      "         [[  29.,   -2.,    1.,  ...,   -2.,    4.,   64.],\n",
      "          [  19.,   -4.,    8.,  ...,   -6.,    9.,   99.],\n",
      "          [  12.,   13.,   13.,  ...,   31.,   40.,   80.],\n",
      "          ...,\n",
      "          [   6.,  -18.,   31.,  ...,  -88.,   40.,   75.],\n",
      "          [ -10.,   -4.,  -21.,  ...,  -95.,   25.,   56.],\n",
      "          [  10.,   16.,   22.,  ...,  -60.,   67.,   83.]]],\n",
      "\n",
      "\n",
      "        [[[   4.,  -14.,  -17.,  ...,    6.,   11.,   -3.],\n",
      "          [ -10.,  -61.,  -55.,  ...,  -21.,    0.,  -16.],\n",
      "          [  12.,  -42.,  -71.,  ...,    0.,   -7.,   -2.],\n",
      "          ...,\n",
      "          [  13.,  -50.,  -78.,  ...,   -1.,  -46.,  -61.],\n",
      "          [  17.,  -41.,  -73.,  ...,  -49.,  -57.,   18.],\n",
      "          [  18.,  -23.,  -36.,  ...,  -12.,    0.,   33.]],\n",
      "\n",
      "         [[  55.,   21.,    8.,  ...,   11.,   11.,   33.],\n",
      "          [  73.,   54.,   55.,  ...,   22.,   29.,   34.],\n",
      "          [  55.,   19.,   23.,  ...,   26.,   28.,   31.],\n",
      "          ...,\n",
      "          [  54.,    9.,   13.,  ...,  -51.,  -50.,  -49.],\n",
      "          [  61.,   -1.,   22.,  ...,  -21.,    4.,    7.],\n",
      "          [   3.,  -28.,  -29.,  ...,   63.,   66.,   50.]],\n",
      "\n",
      "         [[ -95.,  -25.,  -28.,  ...,  -10.,  -20.,  -22.],\n",
      "          [  12.,  -34.,  -41.,  ...,   10.,  -40.,  -23.],\n",
      "          [ -16.,  -29.,  -20.,  ...,  -26.,  -11.,  -26.],\n",
      "          ...,\n",
      "          [ -24.,   -4.,  -13.,  ...,  -81.,   32.,   27.],\n",
      "          [ -36.,    3.,  -10.,  ...,  -22.,  -41.,  -88.],\n",
      "          [  72.,   -8.,   15.,  ...,   18.,   -4.,  -34.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[  38.,   59.,    3.,  ...,   47.,   34.,   51.],\n",
      "          [  21.,   55.,   27.,  ...,    2.,   14.,   44.],\n",
      "          [   9.,   48.,   41.,  ...,   -9.,    5.,   30.],\n",
      "          ...,\n",
      "          [  10.,   55.,   49.,  ...,   34.,   99.,   29.],\n",
      "          [  24.,   72.,   55.,  ...,  -18.,  -17.,  -61.],\n",
      "          [ -11.,   23.,   60.,  ...,  -37.,  -45.,  -25.]],\n",
      "\n",
      "         [[  47.,   78.,   75.,  ...,   -7.,  -15.,  -24.],\n",
      "          [ -10.,  -12.,  -33.,  ...,    8.,   -4.,   12.],\n",
      "          [  -2.,   17.,  -20.,  ...,   -2.,   15.,   -9.],\n",
      "          ...,\n",
      "          [ -12.,    3.,  -19.,  ...,  183.,  179.,   92.],\n",
      "          [  -6.,   18.,  -17.,  ...,   73.,   -1.,  -16.],\n",
      "          [ 100.,  100.,  142.,  ...,  -73.,  -45.,  -20.]],\n",
      "\n",
      "         [[  33.,   -2.,  -19.,  ...,   42.,   33.,   31.],\n",
      "          [  29.,    4.,  -22.,  ...,   44.,   42.,   45.],\n",
      "          [  19.,  -13.,  -21.,  ...,   28.,   39.,   33.],\n",
      "          ...,\n",
      "          [   8.,  -22.,  -37.,  ...,   26.,   44.,   60.],\n",
      "          [  14.,  -22.,  -35.,  ...,   59.,   51.,   15.],\n",
      "          [  37.,   31.,   38.,  ...,   22.,   35.,   13.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[   1.,  -23.,   -1.,  ...,   -4.,  -31.,  -69.],\n",
      "          [ -30.,  -61.,  -91.,  ...,  -46., -100.,  -76.],\n",
      "          [  21.,    2.,   -1.,  ...,  -28., -104., -108.],\n",
      "          ...,\n",
      "          [ -52.,  -14.,  -12.,  ...,  -47., -141.,  -96.],\n",
      "          [ -53.,  -15.,  -21.,  ...,   -8.,  -99.,  -92.],\n",
      "          [ -34.,  -19.,  -15.,  ...,   -4.,  -67.,  -69.]],\n",
      "\n",
      "         [[  52.,   11.,   12.,  ...,   14.,   13.,   29.],\n",
      "          [  43.,    1.,    4.,  ...,   36.,   40.,   53.],\n",
      "          [-117., -168., -174.,  ...,  112.,   35.,   44.],\n",
      "          ...,\n",
      "          [  11.,   37.,   48.,  ...,  154.,  -18.,   45.],\n",
      "          [   0.,   26.,   28.,  ...,  139.,  -21.,   35.],\n",
      "          [  40.,   77.,   87.,  ...,   58.,  -32.,   24.]],\n",
      "\n",
      "         [[-113.,  -32.,  -30.,  ...,  -19.,  -18.,    2.],\n",
      "          [ -63.,  -78.,  -88.,  ...,   22.,  -39.,  -35.],\n",
      "          [  96.,  -60.,  -47.,  ..., -258.,    5.,  -10.],\n",
      "          ...,\n",
      "          [  -1.,  -15.,  -10.,  ...,  -57.,  -32.,  -45.],\n",
      "          [   8.,  -35.,  -12.,  ...,  -30.,  -48.,  -46.],\n",
      "          [  19.,   11.,   16.,  ...,  102.,  -35.,  -65.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[  33.,   47.,   31.,  ...,   43.,   56.,  112.],\n",
      "          [  38.,   71.,   74.,  ...,   70.,   51.,  115.],\n",
      "          [ -38.,  -48.,   -9.,  ...,   55.,  112.,  113.],\n",
      "          ...,\n",
      "          [  26.,   -7.,  -15.,  ...,   31.,  123.,  116.],\n",
      "          [   3.,  -17.,  -32.,  ...,   22.,  112.,  128.],\n",
      "          [   1.,  -22.,  -33.,  ...,  -23.,   38.,   64.]],\n",
      "\n",
      "         [[  42.,   47.,   34.,  ...,   44.,   47.,   14.],\n",
      "          [ -41.,  -50.,  -60.,  ...,    1.,  -24.,  -24.],\n",
      "          [ 283.,  346.,  373.,  ...,  -51.,  -24.,   -9.],\n",
      "          ...,\n",
      "          [   0.,   -8.,  -24.,  ...,    7.,   17.,  -14.],\n",
      "          [  25.,   -1.,    8.,  ...,   31.,   45.,   15.],\n",
      "          [ -55.,  -44.,  -58.,  ...,  107.,   85.,   50.]],\n",
      "\n",
      "         [[  32.,   -2.,   -1.,  ...,   -3.,    7.,   60.],\n",
      "          [  15.,  -21.,    8.,  ...,   24.,   35.,   87.],\n",
      "          [  10.,    2.,   -4.,  ...,   38.,   10.,   94.],\n",
      "          ...,\n",
      "          [  33.,   27.,   17.,  ...,   23.,   -8.,   92.],\n",
      "          [  29.,   27.,   21.,  ...,   24.,  -17.,   91.],\n",
      "          [  27.,   36.,   26.,  ...,   37.,   25.,  109.]]],\n",
      "\n",
      "\n",
      "        [[[   1.,  -23.,   -1.,  ...,   -3.,  -31.,  -69.],\n",
      "          [ -28.,  -59.,  -78.,  ...,  -40., -101.,  -76.],\n",
      "          [  32.,    9.,    8.,  ...,  -17., -100., -108.],\n",
      "          ...,\n",
      "          [ -30.,  -15.,   39.,  ...,  -58., -138.,  -96.],\n",
      "          [ -45.,   -3.,  -36.,  ...,   -8.,  -97.,  -92.],\n",
      "          [ -43.,  -22.,    7.,  ...,  -10.,  -65.,  -69.]],\n",
      "\n",
      "         [[  52.,   11.,   12.,  ...,    8.,   18.,   29.],\n",
      "          [  40.,   -3.,    6.,  ...,   21.,   42.,   53.],\n",
      "          [-137., -187., -179.,  ...,  114.,   35.,   44.],\n",
      "          ...,\n",
      "          [  10.,   53.,   30.,  ...,  154.,  -13.,   45.],\n",
      "          [ -16.,    2.,   24.,  ...,  138.,  -13.,   35.],\n",
      "          [  43.,   81.,   78.,  ...,   55.,  -32.,   24.]],\n",
      "\n",
      "         [[-113.,  -32.,  -30.,  ...,  -20.,  -24.,    2.],\n",
      "          [ -62.,  -78.,  -83.,  ...,   30.,  -47.,  -35.],\n",
      "          [ 103.,  -59.,  -63.,  ..., -272.,   12.,  -10.],\n",
      "          ...,\n",
      "          [ -27.,   14.,   98.,  ...,  -52.,  -54.,  -45.],\n",
      "          [  13.,  -33.,  -16.,  ...,  -33.,  -52.,  -46.],\n",
      "          [  19.,   12.,   25.,  ...,  110.,  -39.,  -65.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[  33.,   47.,   31.,  ...,   38.,   60.,  112.],\n",
      "          [  47.,   87.,   84.,  ...,   60.,   54.,  115.],\n",
      "          [ -39.,  -46.,   -5.,  ...,   57.,  116.,  113.],\n",
      "          ...,\n",
      "          [   3.,  -34.,  -66.,  ...,   39.,  119.,  116.],\n",
      "          [  -5.,  -25.,  -33.,  ...,   29.,  110.,  128.],\n",
      "          [  -8.,  -24.,  -48.,  ...,  -13.,   40.,   64.]],\n",
      "\n",
      "         [[  42.,   47.,   34.,  ...,   44.,   45.,   14.],\n",
      "          [ -38.,  -41.,  -45.,  ...,   24.,  -16.,  -24.],\n",
      "          [ 288.,  352.,  361.,  ...,  -82.,  -23.,   -9.],\n",
      "          ...,\n",
      "          [  -3.,  -27.,  -66.,  ...,    8.,   18.,  -14.],\n",
      "          [  35.,   35.,   27.,  ...,   19.,   49.,   15.],\n",
      "          [ -51.,  -64.,  -72.,  ...,  112.,   85.,   50.]],\n",
      "\n",
      "         [[  32.,   -2.,   -1.,  ...,   -6.,    6.,   60.],\n",
      "          [  11.,  -28.,    8.,  ...,   10.,   35.,   87.],\n",
      "          [   5.,   -1.,   -3.,  ...,   22.,    7.,   94.],\n",
      "          ...,\n",
      "          [  13.,   -9.,  -46.,  ...,   34.,   -4.,   92.],\n",
      "          [  19.,   20.,   17.,  ...,   30.,  -12.,   91.],\n",
      "          [  23.,   34.,    6.,  ...,   43.,   25.,  109.]]],\n",
      "\n",
      "\n",
      "        [[[ -26., -171.,   41.,  ...,  -12.,   -4.,   25.],\n",
      "          [ -45., -255.,  -27.,  ...,  -93.,  -17.,   -6.],\n",
      "          [ -49., -219.,  -13.,  ...,  -30.,  -60.,   12.],\n",
      "          ...,\n",
      "          [  -8.,  -50.,   -8.,  ...,  -19.,  -66.,  -94.],\n",
      "          [  13.,  -37.,  -21.,  ...,  -18.,  -57.,  -96.],\n",
      "          [  18.,   -8.,   13.,  ...,    1.,  -26.,  -71.]],\n",
      "\n",
      "         [[  75.,  132.,  -98.,  ...,   13.,  -21.,   19.],\n",
      "          [  79.,  168.,  -33.,  ...,   55.,   19.,   13.],\n",
      "          [  69.,  135.,  -77.,  ...,   12.,   51.,   21.],\n",
      "          ...,\n",
      "          [  72.,   42.,   45.,  ...,   33.,   34.,   51.],\n",
      "          [  62.,    6.,    7.,  ...,  -13.,   -5.,   35.],\n",
      "          [   3.,  -31.,  -25.,  ...,  -20.,  -14.,   27.]],\n",
      "\n",
      "         [[-132.,  -38.,  133.,  ...,  -18.,   32.,  -32.],\n",
      "          [  -3.,  -77.,  -70.,  ...,  -69.,  -23.,   11.],\n",
      "          [ -15.,  -65.,  -63.,  ...,  -48., -117.,    3.],\n",
      "          ...,\n",
      "          [  -1.,    6.,   18.,  ...,  -24.,  -59.,  -79.],\n",
      "          [ -41.,  -24.,  -44.,  ...,   -2.,  -11.,  -31.],\n",
      "          [  72.,  -12.,  -26.,  ...,   -5.,   -1.,  -56.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[  31.,  257.,  -34.,  ...,   70.,    1.,   -8.],\n",
      "          [  38.,  250.,  -45.,  ...,   80.,   23.,  -10.],\n",
      "          [  20.,  236.,  -35.,  ...,   15.,   72.,   14.],\n",
      "          ...,\n",
      "          [  13.,   48.,    3.,  ...,   13.,   41.,   88.],\n",
      "          [  25.,   69.,   43.,  ...,   43.,   59.,  122.],\n",
      "          [ -11.,   14.,   10.,  ...,    9.,   27.,   60.]],\n",
      "\n",
      "         [[  43.,    8.,    7.,  ...,  -42.,   -7.,  -26.],\n",
      "          [ -47.,  -21.,  -49.,  ...,  -25.,  -27.,   35.],\n",
      "          [ -31.,    7.,   41.,  ...,   63.,   -1.,  -27.],\n",
      "          ...,\n",
      "          [ -16.,  -13.,   -6.,  ...,   12.,   12.,   -1.],\n",
      "          [  -4.,   26.,   20.,  ...,   20.,   17.,   15.],\n",
      "          [ 100.,   95.,  108.,  ...,   99.,   89.,   50.]],\n",
      "\n",
      "         [[   5.,  121.,   -2.,  ...,    1.,    6.,   -2.],\n",
      "          [ -31.,  155.,   13.,  ...,   23.,  -26.,    3.],\n",
      "          [ -44.,  124.,    0.,  ...,   53.,   48.,   -8.],\n",
      "          ...,\n",
      "          [  25.,   11.,   25.,  ...,   11.,   14.,  100.],\n",
      "          [  20.,   -4.,   15.,  ...,   -1.,    1.,   84.],\n",
      "          [  37.,   29.,   52.,  ...,   47.,   40.,  105.]]]], device='cuda:0',\n",
      "       grad_fn=<CudnnConvolutionBackward>)\n"
     ]
    }
   ],
   "source": [
    "conv_int = torch.nn.Conv2d(in_channels = 8, out_channels=8, kernel_size = 3, padding=1, bias = False)\n",
    "conv_int.weight = torch.nn.parameter.Parameter(weight_int)\n",
    "relu = nn.ReLU()\n",
    "bn = nn.BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True).to(device)\n",
    "output_int = conv_int(x_int)\n",
    "output_int = (output_int+x0_int)*w_delta*x_delta\n",
    "output_recovered = relu(output_int)\n",
    "print(conv_int(x_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "entitled-barbados",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1251, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "difference = abs(save_output.outputs[3][0] - output_recovered )\n",
    "print(difference.mean())  ## It should be small, e.g.,2.3 in my trainned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "minimal-serbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0_int.size()\n",
    "X0 = x0_int[0]\n",
    "X0 = torch.reshape(X0, (X0.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "5672365f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1024])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X0.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "ae77e2ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X0 = X0[:, 0:8]\n",
    "X0.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "23744ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_precision = 16\n",
    "file = open('./resnet_out/residual.txt', 'w') #write to file\n",
    "file.write('#time0row7[msb-lsb],time0row6[msb-lst],....,time0row0[msb-lst]#\\n')\n",
    "file.write('#time1row7[msb-lsb],time1row6[msb-lst],....,time1row0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for i in range(X0.size(1)):  # time step\n",
    "    for j in range(X0.size(0)): # row #\n",
    "        X0_bin = '{0:016b}'.format(int(X0[7-j,i].item()+0.001))\n",
    "        for k in range(bit_precision):\n",
    "            file.write(X0_bin[k])        \n",
    "        #file.write(' ')  # for visibility with blank between words, you can use\n",
    "    file.write('\\n')\n",
    "file.close() #close file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "54019d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[49., 35., 35., 35., 35., 35., 35., 56.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [49., 14., 14., 14., 14., 14., 14.,  7.],\n",
       "        [28., 14., 14., 14., 14., 14., 14., 14.],\n",
       "        [ 0.,  7.,  7.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [77., 14., 14., 14., 14., 14., 14., 21.],\n",
       "        [42., 35., 35., 35., 35., 35., 35., 35.],\n",
       "        [ 7., 21., 21., 21., 28., 28., 21., 28.]], device='cuda:0',\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "008a4f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-11.,  31.,  33.,  35.,  48.,  22.,  28.,  65.],\n",
      "        [  8.,  37.,  46.,  50.,  38.,  42.,  35.,  21.],\n",
      "        [ 30.,  16.,  19.,  19.,  21.,  21.,  -8.,  34.],\n",
      "        [ 28.,   7.,   6.,   9.,  13.,  35.,  10.,  -2.],\n",
      "        [ 19.,   9.,   5.,  -5.,  -4.,   5.,   1.,  20.],\n",
      "        [109.,  -2.,  -1.,  -2.,  -7., -12.,  30., -53.],\n",
      "        [ 21., -41., -35., -32., -20., -27., -35., -24.],\n",
      "        [ 54.,  43.,  40.,  39.,  37.,  43.,  25.,  25.]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "answer = out + X0\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "5dfe8b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_precision = 16\n",
    "file = open('./resnet_out/answer.txt', 'w') #write to file\n",
    "file.write('#time0col7[msb-lsb],time0col6[msb-lst],....,time0col0[msb-lst]#\\n')\n",
    "file.write('#time1col7[msb-lsb],time1col6[msb-lst],....,time1col0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for i in range(answer.size(1)):\n",
    "    for j in range(answer.size(0)):\n",
    "        if (answer[7-j,i].item()<0):\n",
    "            ans_bin = '{0:016b}'.format(int(answer[7-j,i].item()+2**bit_precision+0.001))\n",
    "        else:\n",
    "            ans_bin = '{0:016b}'.format(int(answer[7-j,i].item()+0.001))\n",
    "        for k in range(bit_precision):\n",
    "            file.write(ans_bin[k])\n",
    "        #file.write(' ')  # for visibility with blank between words, you can use\n",
    "    file.write('\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "37debf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./resnet_out/address.txt','r')\n",
    "line = f.readlines()\n",
    "bit_precision =11\n",
    "file = open('./resnet_out/acc_address.txt','w')\n",
    "for item in line:\n",
    "    add = '{0:011b}'.format(int(item))\n",
    "    for k in range(bit_precision):\n",
    "        file.write(add[k])\n",
    "    file.write('\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a897a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
